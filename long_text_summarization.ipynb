{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2dc435-64b1-4159-94c9-aea733ef8cb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generative AI for Document Analysis and Summarization\n",
    "\n",
    "From the blog post: [Mastering Long Document Insights: Advanced Summarization with Amazon Bedrock and Anthropic Claude 2 Foundation Model](https://garystafford.medium.com/mastering-long-document-insights-advanced-summarization-with-amazon-bedrock-and-anthropic-claude-2-2fe13d5ae8d8). In this post, we move beyond simple summarization and explore advanced techniques to analyze long texts using Amazon Bedrock and the Anthropic Claude 2 Foundation Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "272a1715-8ca7-41b6-a75a-e193991e0372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "python -m pip install pip -Uq --root-user-action=ignore\n",
    "python -m pip install -r requirements.txt -Uq --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e939288-70d6-471d-9e13-2f8874f64511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anthropic                            0.5.0\n",
      "boto3                                1.28.78\n",
      "botocore                             1.31.78\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "python -m pip list | grep 'anthropic\\|boto3\\|botocore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8fea76-3bc4-4d48-8d7b-5c15336636f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "from statistics import mean\n",
    "import string\n",
    "\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f448b4-9d1f-4bf2-8bda-369dacab26b2",
   "metadata": {},
   "source": [
    "## Load and Prepare Long Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5df648d-b7e4-4c08-b33f-ff3168d08c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular expressions to split the book into chapters\n",
    "def split_book(book_text):\n",
    "    # Specific to this Gutenberg eBooks format\n",
    "    chapters = re.split(r\"^CHAPTER [IVXLCDM]+$\", book_text, flags=re.MULTILINE)\n",
    "\n",
    "    # remove everything prior to chapter 1\n",
    "    chapters.pop(0)\n",
    "\n",
    "    # Split the last chapter into two parts and remove everything after \"THE END\"\n",
    "    chapter26 = re.split(r\"^.*THE END.*$\", chapters[26], flags=re.MULTILINE)[0]\n",
    "    chapters.pop(26)\n",
    "    chapters.append(chapter26)\n",
    "\n",
    "    return chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a67b92d-300d-4eea-95ff-70e4c3a677fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify the path to the text file you want to read\n",
    "# https://www.gutenberg.org/cache/epub/345/pg345-images.html\n",
    "file_path = \"./input/dracula.txt\"\n",
    "\n",
    "# Open the file in read mode and read its contents into a string\n",
    "with open(file_path, \"r\") as file:\n",
    "    book_text = file.read()\n",
    "\n",
    "chapters = split_book(book_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afeca78a-a8b0-433a-9223-a36e1177ae63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "JONATHAN HARKER’S JOURNAL\n",
      "(Kept in shorthand.)\n",
      "\n",
      "3 May. Bistritz.—Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning; should have arrived at 6:46, but train was an hour late. Buda-Pesth seems a wonderful place, from the glimpse which I got of it from the train and the little I could walk through the streets. I feared to go very far from the station, as we had arrived late and would start as near the correct time as possible. The impression I had was that we were leaving the West and entering the East; the most western of splendid bridges over the Danube, which is here of noble width and depth, took us among the traditions of Turkish rule.\n",
      "\n",
      "We left in pretty good time, and came after nightfall to Klausenburgh. Here I stopped for the night at the Hotel Royale. I had for dinner, or rather supper, a chicken done up some way with red pepper, which was very good but thirsty. (Mem., get recipe for Mina.) I asked the waiter, and he said it was called “paprika hendl,” and that, as it was a national dish, I should be able to get it anywhere along the Carpathians. I found my smattering of German very useful here; indeed, I don’t know how I should be able to get on without it.\n",
      "\n",
      "Having had some time at my disposal when in London, I had visited the British Museum, and made search among the books and maps in the library regarding Transylvania; it had struck me that some foreknowledge of the country could hardly fail to have some importance in dealing with a nobleman of that country. I find that the district he named is in the extreme east of the country, just on the borders of three states, Transylvania, Moldavia and Bukovina, in the midst of the Carpathian mountains; one of the wildest and least known portions of Europe. I was not able to light on any map or work giving the exact locality of the Castle Dracula, as there are no maps of this country as yet to compare with our own Ordnance Survey maps; but I found that Bistritz, the post town named by Count Dracula, is a fairly well-known place. I shall\n"
     ]
    }
   ],
   "source": [
    "print(chapters[0][0:2048])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c430926-b3ab-404d-8964-0baf3023a07a",
   "metadata": {},
   "source": [
    "## Long Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dcd3178-4589-4afe-9eb4-ff2d26a3b0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chpt\tparas\twords\tchars\ttokens\tratio\n",
      "----------------------------------------------\n",
      "1\t39\t5,547\t30,624\t7,218\t4.24\n",
      "2\t62\t5,305\t28,510\t6,833\t4.17\n",
      "3\t46\t5,571\t29,805\t7,075\t4.21\n",
      "4\t86\t5,703\t30,267\t7,338\t4.12\n",
      "5\t28\t3,390\t18,019\t4,650\t3.88\n",
      "6\t64\t5,299\t29,195\t7,524\t3.88\n",
      "7\t62\t5,424\t29,964\t7,120\t4.21\n",
      "8\t59\t6,044\t32,637\t7,970\t4.09\n",
      "9\t64\t5,709\t30,180\t7,477\t4.04\n",
      "10\t100\t5,623\t30,817\t7,706\t4.00\n",
      "11\t78\t4,754\t26,991\t7,014\t3.85\n",
      "12\t95\t6,993\t37,944\t9,372\t4.05\n",
      "13\t107\t6,242\t34,198\t8,490\t4.03\n",
      "14\t97\t6,053\t32,612\t8,277\t3.94\n",
      "15\t101\t5,485\t29,787\t7,509\t3.97\n",
      "16\t62\t4,381\t23,928\t5,895\t4.06\n",
      "17\t80\t5,264\t29,074\t7,140\t4.07\n",
      "18\t84\t6,615\t35,948\t8,924\t4.03\n",
      "19\t46\t5,505\t29,462\t7,041\t4.18\n",
      "20\t104\t5,467\t31,241\t7,883\t3.96\n",
      "21\t69\t5,905\t32,220\t7,940\t4.06\n",
      "22\t65\t5,249\t28,130\t6,822\t4.12\n",
      "23\t84\t5,403\t29,551\t7,351\t4.02\n",
      "24\t75\t6,057\t32,123\t7,924\t4.05\n",
      "25\t87\t5,907\t32,612\t8,153\t4.00\n",
      "26\t106\t6,818\t37,084\t9,266\t4.00\n",
      "27\t78\t7,733\t40,677\t10,055\t4.05\n",
      "\n",
      "---\n",
      "Complete Novel (raw long text)\n",
      "---\n",
      "sum chars:\t856,545\n",
      "sum words:\t658,827\n",
      "sum tokens:\t211,209\n",
      "\n",
      "---\n",
      "Chapters\n",
      "---\n",
      "chpt count:\t27\n",
      "---\n",
      "min paras:\t28\n",
      "max paras:\t107\n",
      "mean words:\t75\n",
      "sum paras:\t2,028\n",
      "---\n",
      "min words:\t3,390\n",
      "max words:\t7,733\n",
      "mean words:\t5,683\n",
      "sum words:\t153,446\n",
      "---\n",
      "min chars:\t18,019\n",
      "max chars:\t40,677\n",
      "mean chars:\t30,874\n",
      "sum chars:\t833,600\n",
      "---\n",
      "min tokens:\t4,650\n",
      "max tokens:\t10,055\n",
      "mean tokens:\t7,628\n",
      "sum tokens:\t205,967\n",
      "---\n",
      "min chars/token:\t3.85\n",
      "max chars/token:\t4.24\n",
      "mean chars/token:\t4.05\n"
     ]
    }
   ],
   "source": [
    "chapter_nums = []\n",
    "character_count = []\n",
    "word_count = []\n",
    "token_count = []\n",
    "char_token_ratio = []\n",
    "para_count = []\n",
    "\n",
    "client = Anthropic()\n",
    "\n",
    "print(\"chpt\\tparas\\twords\\tchars\\ttokens\\tratio\")\n",
    "print(f\"----------------------------------------------\")\n",
    "\n",
    "\n",
    "for i, chapter in enumerate(chapters):\n",
    "    try:\n",
    "        chapter_nums.append(f\"chpt {i+1}\")\n",
    "\n",
    "        token_count_tmp = client.count_tokens(chapter.strip())\n",
    "        token_count.append(token_count_tmp)\n",
    "\n",
    "        character_count_tmp = len(chapter.strip())\n",
    "        character_count.append(character_count_tmp)\n",
    "\n",
    "        word_count_tmp = sum(\n",
    "            [i.strip(string.punctuation).isalpha() for i in chapter.split()]\n",
    "        )\n",
    "        word_count.append(word_count_tmp)\n",
    "\n",
    "        para_count_tmp = len(chapter.split(\"\\n\\n\"))\n",
    "        para_count.append(para_count_tmp)\n",
    "\n",
    "        char_token_ratio_tmp = character_count_tmp / token_count_tmp\n",
    "        char_token_ratio.append(char_token_ratio_tmp)\n",
    "\n",
    "        print(\n",
    "            f\"{i+1}\\t{para_count_tmp:,.0f}\\t{word_count_tmp:,.0f}\\t{character_count_tmp:,.0f}\\t{token_count_tmp:,.0f}\\t{char_token_ratio_tmp:,.2f}\"\n",
    "        )\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "print(\"\\n---\")\n",
    "print(f\"Complete Novel (raw long document)\")\n",
    "print(f\"---\")\n",
    "print(f\"sum chars:\\t{len(book_text):,.0f}\")\n",
    "print(\n",
    "    f\"sum words:\\t{sum([i.strip(string.punctuation).isalpha() for i in book_text]):,.0f}\"\n",
    ")\n",
    "print(f\"sum tokens:\\t{client.count_tokens(book_text):,.0f}\")\n",
    "\n",
    "print(\"\\n---\")\n",
    "print(\"Chapters\")\n",
    "print(f\"---\")\n",
    "print(f\"chpt count:\\t{len(chapters)}\")\n",
    "print(f\"---\")\n",
    "print(f\"min paras:\\t{min(para_count):,.0f}\")\n",
    "print(f\"max paras:\\t{max(para_count):,.0f}\")\n",
    "print(f\"mean words:\\t{int(mean(para_count)):,.0f}\")\n",
    "print(f\"sum paras:\\t{sum(para_count):,.0f}\")\n",
    "print(\"---\")\n",
    "print(f\"min words:\\t{min(word_count):,.0f}\")\n",
    "print(f\"max words:\\t{max(word_count):,.0f}\")\n",
    "print(f\"mean words:\\t{int(mean(word_count)):,.0f}\")\n",
    "print(f\"sum words:\\t{sum(word_count):,.0f}\")\n",
    "print(\"---\")\n",
    "print(f\"min chars:\\t{min(character_count):,.0f}\")\n",
    "print(f\"max chars:\\t{max(character_count):,.0f}\")\n",
    "print(f\"mean chars:\\t{int(mean(character_count)):,.0f}\")\n",
    "print(f\"sum chars:\\t{sum(character_count):,.0f}\")\n",
    "print(\"---\")\n",
    "print(f\"min tokens:\\t{min(token_count):,.0f}\")\n",
    "print(f\"max tokens:\\t{max(token_count):,.0f}\")\n",
    "print(f\"mean tokens:\\t{int(mean(token_count)):,.0f}\")\n",
    "print(f\"sum tokens:\\t{int(sum(token_count)):,.0f}\")\n",
    "print(\"---\")\n",
    "print(f\"min chars/token:\\t{min(char_token_ratio):,.2f}\")\n",
    "print(f\"max chars/token:\\t{max(char_token_ratio):,.2f}\")\n",
    "print(f\"mean chars/token:\\t{mean(char_token_ratio):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d57a8db-5a86-4008-ac1f-36f1bc6e0966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# data = {\n",
    "#     \"chars\": character_count,\n",
    "#     \"words\": word_count,\n",
    "#     \"tokens\": token_count,\n",
    "#     \"char/token\": char_token_ratio,\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data, index=chapter_nums)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b23a3-ccb6-47cb-9774-6a79314f6a22",
   "metadata": {},
   "source": [
    "## Long Text Summarization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95ea259-f782-4333-913f-f97137c8fdcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0393354c-fe5d-4056-b0f8-636518fdb064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_bedrock = boto3.client(\"bedrock-runtime\", \"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364b3702-2aa8-453c-8e8f-376c49f39308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_summary(prompt):\n",
    "    try:\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"prompt\": f\"\\n\\nHuman: {prompt}\\n\\nAssistant:\",\n",
    "                \"max_tokens_to_sample\": 4096,\n",
    "                \"temperature\": 0.2,\n",
    "                \"top_k\": 250,\n",
    "                \"top_p\": 1,\n",
    "                \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "            }\n",
    "        )\n",
    "        # print(f\"Request body: {body}\")\n",
    "\n",
    "        accept = \"application/json\"\n",
    "        content_type = \"application/json\"\n",
    "\n",
    "        response = client_bedrock.invoke_model(\n",
    "            body=body,\n",
    "            modelId=\"anthropic.claude-v2\",\n",
    "            accept=accept,\n",
    "            contentType=content_type,\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        # print(f\"Response body: {response_body}\")\n",
    "\n",
    "        # remove the first line of text that explains the task completed\n",
    "        # e.g. \" Here are three hypothetical questions that the passage could help answer:\\n\\n\"\n",
    "        formatted_response = \"\"\n",
    "        try:\n",
    "            formatted_response = (\n",
    "                response_body.get(\"completion\").split(\"\\n\", 2)[2].strip()\n",
    "            )\n",
    "        except:\n",
    "            formatted_response = response_body.get(\"completion\")\n",
    "        return formatted_response\n",
    "    except ClientError as ex:\n",
    "        print(ex)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab144686-2f9e-4d31-9186-22dd8ea0fa8a",
   "metadata": {},
   "source": [
    "### Basic Prompting\n",
    "\n",
    "Progressively more precise prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "827edf91-025d-460e-8ec8-7c3d75fcdbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The chapter is from Jonathan Harker's journal, written in shorthand. He is traveling to Transylvania to meet Count Dracula.\n",
      "\n",
      "- Harker takes a train from Munich to Buda-Pesth, where he gets an impression of entering the East. He continues on to Klausenburgh and has dinner at his hotel. \n",
      "\n",
      "- At Bistritz, he stays at the Golden Krone Hotel. The landlady seems reluctant for him to continue his journey the next day. \n",
      "\n",
      "- Harker departs Bistritz in a coach. His fellow passengers make signs to ward off evil and warn him of danger ahead. \n",
      "\n",
      "- After nightfall, the passengers grow excited as they near the Borgo Pass. A mysterious driver arrives to take Harker in his calèche the rest of the way.\n",
      "\n",
      "- They travel through the Borgo Pass at night. Wolves can be heard howling. The driver seems unconcerned. \n",
      "\n",
      "- Nearing Castle Dracula, Harker sees blue flames in the darkness which seem to frighten the horses. The driver leaves to investigate.\n",
      "\n",
      "- They arrive at the castle, an ancient, immense, ruined structure with no light in the windows.\n"
     ]
    }
   ],
   "source": [
    "# basic prompt example #1\n",
    "\n",
    "prompt = f\"\"\"Write a short summary of the following chapter:\n",
    "    {chapters[0].strip()}\"\"\"\n",
    "\n",
    "print(create_summary(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9d5e1db-afa4-416b-80f2-ce4bb504952d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jonathan Harker describes his journey from Munich to Transylvania to meet Count Dracula, detailing the beautiful but ominous landscape and strange encounters with locals who warn him against continuing. Upon arriving at the Borgo Pass, he is met by a driver in Dracula's carriage who takes him through the mountains to the Count's ruined castle. Harker feels unease about his mysterious host and the howling wolves that seem to surround them.\n"
     ]
    }
   ],
   "source": [
    "# basic prompt example #2\n",
    "\n",
    "prompt = f\"\"\"Write a concise, grammatically correct, single-paragraph summary of the following chapter:\n",
    "    {chapters[0].strip()}\"\"\"\n",
    "\n",
    "print(create_summary(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cb690b6-54dd-4243-a67c-57bc4f2e7f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jonathan Harker's journal describes his journey from Munich to Transylvania to meet Count Dracula, depicting the beautiful but ominous Carpathian landscape and recounting strange events and superstitions that foreshadow Dracula's supernatural nature. After delays and mysteries, Harker arrives at the Borgo Pass as wolves howl, where a carriage takes him through the mountains to Dracula's ruined castle.\n"
     ]
    }
   ],
   "source": [
    "# basic prompt example #3\n",
    "\n",
    "prompt = f\"\"\"### INSTRUCTIONS ###\n",
    "    Write a concise, grammatically correct, single-paragraph summary of the following chapter.\n",
    "    \n",
    "    ### CHAPTER ###\n",
    "    {chapters[0].strip()}\"\"\"\n",
    "\n",
    "print(create_summary(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4092a857-9573-481e-be0c-ba0f8a6d64a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chapter is from the journal of Jonathan Harker, who is traveling through the Carpathian Mountains on his way to meet Count Dracula. Harker makes his way from Munich to Bistritz despite train delays, ominous warnings from locals about evil forces, and his own growing unease. He finally departs in a calèche driven by a mysterious figure with bright red eyes to an ancient ruined castle, likely Dracula's, after being surrounded by wolves along the way. The chapter establishes the ominous, gothic tone of Harker's journey into this remote region and his approaching encounter with the sinister Count Dracula.\n"
     ]
    }
   ],
   "source": [
    "# basic prompt example #4\n",
    "\n",
    "prompt = f\"\"\"Write a concise, grammatically correct, single-paragraph summary of the chapter's main points, events, and ideas contained inside the <chapter><\\chapter> XML tags below.  \n",
    "    The Assistant will refrain from using bullet-point lists.\n",
    "    The Assistant will refrain from including XML tags in the response.\n",
    "    \n",
    "    <chapter>\n",
    "    {chapters[0].strip()}\n",
    "    </chapter>\"\"\"\n",
    "\n",
    "print(create_summary(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e819c-d4a7-4936-aac0-45d0cb59a70d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate Chapter-level Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a8be050-ab48-4b67-a31f-9931e48a4486",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 03:01:35.369900\n",
      "Finish time: 2023-11-06 03:09:13.529252\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level summaries\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Write a concise, grammatically correct, single-paragraph summary of the chapter's main points, events, and ideas contained inside the <chapter><\\chapter> XML tags below. \n",
    "            The Assistant will refrain from using bullet-point lists.\n",
    "            The Assistant will refrain from including XML tags in the response.\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_chapter_summaries.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b933b3-83bb-46da-b315-78e7c20e276a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate Summary of Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3fcb369-e950-4999-8c61-73e51a01bed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 16:33:22.706006\n",
      "Finish time: 2023-11-06 16:33:52.935164\n"
     ]
    }
   ],
   "source": [
    "# generate summary of summaries (using summary from above cell)\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "prompt = f\"\"\"Write a concise, grammatically correct, single-paragraph summary of the novel's main points, events, and ideas, contained inside the <summaries><\\summaries> XML tags below. \n",
    "    The Assistant will refrain from using bullet-point lists.\n",
    "    The Assistant will refrain from including XML tags in the response.\n",
    "    \n",
    "    <summaries>\n",
    "    {summary}\n",
    "    </summaries>\"\"\"\n",
    "\n",
    "try:\n",
    "    chapter_summary = create_summary(prompt)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    exit(0)\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_summary_of_summaries.txt\", \"w\") as f:\n",
    "    f.write(chapter_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10878ec7-f3d3-47ed-a9b7-3fd30906b24b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate Chapter-level Main Character Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7af54d02-c5aa-47b2-ada9-efdd7adfd0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 03:09:33.078763\n",
      "Finish time: 2023-11-06 03:16:54.476901\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level main character descriptions\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Provide a list of the chapter's 3-4 main characters and a brief description of each based on chapter inside the <chapter><\\chapter> XML tags below.          \n",
    "            The Assistant will order the main characters by how many times they are mentioned.\n",
    "            The Assistant will number each character in the list starting at 1.\n",
    "            The Assistant will refrain from including square brackets and XML tags in the response.\n",
    "\n",
    "            Follow the template inside the <template><\\template> XML tags below and replace the placeholders with the relevant information:\n",
    "            <template>\n",
    "            [Number]. [Character]: [Description]\n",
    "            <template>\n",
    "\n",
    "            Here is an example inside the <example><\\example> XML tags below:\n",
    "            <example>\n",
    "            1. Pink Panther: A suave and smooth-talking anthropomorphic animated panther.\n",
    "            </example>\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_character_descs.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63139f-2eac-4ec4-a622-e4b45dbf21b6",
   "metadata": {},
   "source": [
    "### Generate Character Description of Count Dracula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6c9b017-61e1-48ac-8218-9f913112e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 16:35:04.814167\n",
      "Finish time: 2023-11-06 16:35:24.786173\n"
     ]
    }
   ],
   "source": [
    "# generate a description of count dracula (using summary from above cell)\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "try:\n",
    "    prompt = f\"\"\"Write a concise, grammatically correct, single-paragraph description of the main character, Dracula (aka Count Dracula), based on the following individual character descriptions inside the <descriptions><\\descriptions> XML tags below. \n",
    "    The Assistant will refrain from using bullet-point lists.\n",
    "    The Assistant will refrain from including XML tags in the response.\n",
    "    \n",
    "    <descriptions>\n",
    "    {summary}\n",
    "    </descriptions>\"\"\"\n",
    "\n",
    "    chapter_summary = create_summary(prompt)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    exit(0)\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_character_desc_dracula.txt\", \"w\") as f:\n",
    "    f.write(chapter_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86954c31-bf77-42da-a7d9-b1877264ac01",
   "metadata": {},
   "source": [
    "### Generate Chapter-level Character Type Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82bb5e01-db43-452d-bbca-a4bd0bdced49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 03:17:04.158120\n",
      "Finish time: 2023-11-06 03:24:01.066948\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level character type descriptions\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"The following list of character types inside the <character_types></character_types> XML tags below, are often found in fictional literature: \n",
    "            <character_types>\n",
    "            - Protagonist\n",
    "            - Antihero\n",
    "            - Antagonist\n",
    "            - Guide\n",
    "            - Contagonist\n",
    "            - Sidekicks (Deuteragonist)\n",
    "            - Henchmen\n",
    "            - Love Interest\n",
    "            - Temptress\n",
    "            - Confidant\n",
    "            - Foil\n",
    "            </character_types>\n",
    "\n",
    "            Based on this list of character types, give 3-4 examples of character types based on chapter inside the <chapter><\\chapter> XML tags below.\n",
    "            The Assistant will including the character name and an explanation of why.\n",
    "            The Assistant will refrain from including square brackets and XML tags in the response.\n",
    "            \n",
    "            Follow the template inside the <template><\\template> XML tags below and replace the placeholders, in square brackets, with the character name, character type, and explanation:\n",
    "            <template>\n",
    "            [Character_Name] - [Character_Type]: [Explanation]\n",
    "            <template>\n",
    "\n",
    "            Here is an example inside the <example><\\example> XML tags below:\n",
    "            <example>\n",
    "            Love Interest - Minnie Mouse: Mickey Mouse's lifelong romantic interest.\n",
    "            </example>\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_character_types.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e89e1f-c634-4ea6-b715-e6d6ce41f9f3",
   "metadata": {},
   "source": [
    "### Generate Chapter-level Literary Device Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a0f9980-0f8f-4e7c-b5e6-21046517c6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 03:24:01.112827\n",
      "Finish time: 2023-11-06 03:33:41.821564\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level literary device descriptions\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"The following list of literary devices inside the <literary_devices></literary_devices> XML tags below, are often found in fictional literature: \n",
    "            <literary_devices>\n",
    "            Allegory, Alliteration, Allusion, Amplification, Anagram, Analogy, Anthropomorphism, Antithesis, \n",
    "            Chiasmus, Colloquialism, Circumlocution, Epigraph, Euphemism, Foreshadowing, Hyperbole, Imagery, \n",
    "            Metaphor, Mood, Motif, Onomatopoeia, Oxymoron, Paradox, Personification, Portmanteau, Puns, Satire, \n",
    "            Simile, Symbolism, Tone\n",
    "            </literary_devices>\n",
    "\n",
    "            Based on the list of literary devices, give 2-3 examples of literary devices found in the chapter inside the <chapter><\\chapter> XML tags below, and explain why.\n",
    "            The Assistant will use a bullet-point list.\n",
    "            The Assistant will refrain from including square brackets and XML tags in the response.\n",
    "            \n",
    "            Follow the template inside the <template><\\template> XML tags below for your response. Replace the placeholders, in square brackets, with the literary device and the explanation:\n",
    "            <template>\n",
    "            - [Literary_Device]: [Explanation]\n",
    "            <template>\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_literary_devices.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7eb31b-12fc-42a8-8939-b5433b1e2363",
   "metadata": {},
   "source": [
    "### Generate Chapter-level Setting Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f62a3306-7d63-4422-b71e-879633b148f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 03:33:41.867103\n",
      "Finish time: 2023-11-06 03:40:22.419477\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level setting descriptions\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Provide a list of the no more than three settings and a brief description of each setting in the chapter inside the <chapter><\\chapter> XML tags below.\n",
    "            The Assistant will order the settings by how many times they are mentioned in the chapter.\n",
    "            The Assistant will number the list of settings.\n",
    "            The Assistant will refrain from including square brackets and XML tags in the response.\n",
    "            \n",
    "            Follow the template inside the <template><\\template> XML tags below and replace the placeholders, in square brackets, with the relevant information:\n",
    "            <template>\n",
    "            [Number]. [Setting]: [Description]\n",
    "            <template>\n",
    "\n",
    "            Here is an example inside the <example><\\example> XML tags below:\n",
    "            <example>\n",
    "            1. Hoboken, New Jersey: Part of the New York metropolitan area on the banks of the Hudson River across from lower Manhattan, where the story takes place.\n",
    "            </example>\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_chapter_settings.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f40720-a0b1-4291-bf05-6b94cbb70be3",
   "metadata": {},
   "source": [
    "### Descriptive Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f2ace0c-d571-4f99-b72b-45e0d65525de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 03:40:22.457079\n",
      "Finish time: 2023-11-06 03:48:33.752949\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level descriptive adjectives\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Provide a list of 5-6 adjectives that best describe the chapter inside the <chapter><\\chapter> XML tags below. Also, provide a brief reason for each adjective chosen.\n",
    "            The Assistant will refrain from using a bullet-point or numbered list.\n",
    "            The Assistant will refrain from including square brackets and XML tags in the response.\n",
    "            \n",
    "            Follow the template inside the <template><\\template> XML tags below and replace the placeholders, in square brackets, with the relevant information:\n",
    "            <template>\n",
    "            [Adjective]: [Reason]\n",
    "            <template>\n",
    "\n",
    "            Here is an example inside the <example><\\example> XML tags below:\n",
    "            <example>\n",
    "            Relentless: The riders and their hounds were desperately chasing after the poor fox.\n",
    "            </example>\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_adjectives.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80561d00-0459-4b1c-8109-b126788718c4",
   "metadata": {},
   "source": [
    "### Generate Chapter-level Questions and Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa0ad2ad-e4a2-47b5-9681-37f5903472fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 03:48:33.800358\n",
      "Finish time: 2023-11-06 04:02:19.589223\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level questions and answers\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Generate a list of 6 hypothetical questions that the following chapter, inside the <chapter><\\chapter> XML tags below, could be used to answer. \n",
    "            The Assistant will provide both the question and the answer.\n",
    "            The Assistant will refrain from asking overly broad questions.\n",
    "            The Assistant will refrain from using bullet-point lists.\n",
    "            The Assistant will refrain from including square brackets and XML tags in the response.\n",
    "            \n",
    "            Follow the template inside the <template><\\template> XML tags below and replace the placeholders, in square brackets, with the relevant information:\n",
    "            <template>\n",
    "            Q: [Question]\n",
    "            A: [Answer]\n",
    "            <template>\n",
    "\n",
    "            Here is an example inside the <example><\\example> XML tags below:\n",
    "            <example>\n",
    "            Q: What is the weather like in Spain?\n",
    "            A: The rain in Spain stays mainly in the plain.\n",
    "            </example>\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_question_answer.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b870c68-aacc-489b-b1d2-91f5faf14330",
   "metadata": {},
   "source": [
    "### Generate Chapter-level Multiple Choice Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a65588d7-a017-498b-873c-4f0df16ebf73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 04:02:19.635007\n",
      "Finish time: 2023-11-06 04:14:48.910214\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level multiple choice questions\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Generate a list of 6 hypothetical multiple-choice questions that the following chapter, inside the <chapter><\\chapter> XML tags below, could be used to answer. \n",
    "            The Assistant will provide the question, four possible answers lettered a,b,c, and d, and the correct answer.\n",
    "            The Assistant will ask brief, specific questions.\n",
    "            The Assistant will refrain from using bullet-point lists.\n",
    "            The Assistant will refrain from including square brackets and XML tags in the response.\n",
    "            \n",
    "            Follow the template inside the <template><\\template> XML tags below and replace the placeholders, in square brackets, with the relevant information:\n",
    "            Q: [Question]\n",
    "            (a) [Choice_1]\n",
    "            (b) [Choice_2]\n",
    "            (c) [Choice_3]\n",
    "            (d) [Choice_4]\n",
    "            A: (Letter) [Correct_Answer]\n",
    "            <template>\n",
    "\n",
    "            Here is an example inside the <example><\\example> XML tags below:\n",
    "            <example>\n",
    "            Q: What color is fresh grass?\n",
    "            (a) Red\n",
    "            (b) Blue\n",
    "            (c) Green\n",
    "            (d) Yellow\n",
    "            A: (c) Green\n",
    "            </example>\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_multiple_choice.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500aa65-6fb8-4328-abbb-dd803b1705f6",
   "metadata": {},
   "source": [
    "## Using Foundation Models to Optimize Anthropic Prompts\n",
    "\n",
    "Using foundation models to optimize the prompts demonstrated above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1498a30-af93-4f8d-9e51-202fa827f74e",
   "metadata": {},
   "source": [
    "### Using ChatGPT 3.5 to Optimize Prompts\n",
    "\n",
    "[https://chat.openai.com/](https://chat.openai.com/)\n",
    "\n",
    "My prompt: \"Optimize the following prompt, written in Python, for the Anthropic Claude 2 foundation model:...\"\n",
    "\n",
    "Per ChatGPT 3.5, \"This version of the prompt maintains the same instructions and expectations while being more concise and clear.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "616c6438-3d5d-4066-aea2-ea517d7feeac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 14:25:48.316079\n",
      "Finish time: 2023-11-06 14:37:51.989010\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level multiple-choice questions (chatgpt 3.5 optimized)\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Generate 6 multiple-choice questions that pertain to the content of the chapter within the <chapter> XML tags below. Each question should have four answer choices, labeled a, b, c, and d, with one of them being the correct answer. Keep the questions concise and avoid bullet-point lists or the inclusion of square brackets and XML tags in your response.\n",
    "\n",
    "            Use the following template within the <template> XML tags:\n",
    "\n",
    "            Q: [Question]\n",
    "            (a) [Choice_1]\n",
    "            (b) [Choice_2]\n",
    "            (c) [Choice_3]\n",
    "            (d) [Choice_4]\n",
    "            A: (Letter) [Correct_Answer]\n",
    "            <template>\n",
    "\n",
    "            For example, within the <example> XML tags:\n",
    "\n",
    "            <example>\n",
    "            Q: What color is fresh grass?\n",
    "            (a) Red\n",
    "            (b) Blue\n",
    "            (c) Green\n",
    "            (d) Yellow\n",
    "            A: (c) Green\n",
    "            </example>\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_multiple_choice_chatgpt35_optimized.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab625aa6-0cd7-4fed-8c34-e01addc2a511",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using Anthropic Claude to Optimize Prompts\n",
    "\n",
    "[https://claude.ai/chat](https://claude.ai/chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135864d-95ca-4c88-8914-e26256fd3f77",
   "metadata": {},
   "source": [
    "My prompt: \"Optimize the following prompt, written in Python, for the Anthropic Claude 2 foundation model:...\"\n",
    "\n",
    "Per Claude, the key changes:\n",
    "\n",
    "* Simplified instructions to generate 6 Q&A pairs about the chapter.\n",
    "* Asked for brief, specific questions to avoid broad ones.\n",
    "* Removed restrictions about bullet points and tags - the template makes it clear.\n",
    "* Removed the example - the template shows the format.\n",
    "* Streamlined the template to just Q and A.\n",
    "* Used more natural language overall.\n",
    "\n",
    "This focuses the prompt on generating concise Q&A pairs about the key ideas in the chapter. The simplified instructions make it clearer for the model. Removing unnecessary restrictions gives it more freedom. Overall this should produce more targeted questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c4023-75b3-43e0-8e7d-eeffefe2778c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 14:37:52.036256\n",
      "Finish time: 2023-11-06 14:47:46.207766\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level questions and answers (claude-optimized prompt)\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Generate a list of 6 brief, specific questions and answers about the chapter below.\n",
    "\n",
    "            Follow this template:\n",
    "\n",
    "            Q: [Question?]\n",
    "            A: [Answer] \n",
    "\n",
    "            Make the questions clear and focused. Avoid broad, generic questions.  \n",
    "\n",
    "            Keep the questions and answers short. Do not use bullet points, brackets or XML tags.\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()}\n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_question_answer_claude_optimized.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a00fd-4903-4441-8b7e-ff214767bc0a",
   "metadata": {},
   "source": [
    "My prompt: \"Optimize the following prompt, written in Python, for the Anthropic Claude 2 foundation model:...\"\n",
    "\n",
    "Per Claude, the key changes:\n",
    "\n",
    "* Simplified the instructions to focus on generating 6 MCQs for the chapter.\n",
    "* Removed the example - the template makes it clear what's needed.\n",
    "* Streamlined the template to just have the core elements (Q, choices A-D, correct answer).\n",
    "* Asked the model to make questions and answers brief and clear.\n",
    "* Removed unnecessary restrictions like bullet points and XML tags.\n",
    "* Used more natural phrasing overall.\n",
    "\n",
    "This focuses the prompt on the key task, simplifies the instructions, and lets the model know what makes a good MCQ. The result should be more targeted and higher quality questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15f7f33a-9b19-4c59-94f9-7f19fa079ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-11-06 14:59:21.004121\n",
      "Finish time: 2023-11-06 15:12:14.287979\n"
     ]
    }
   ],
   "source": [
    "# generate chapter-level multiple-choice questions (claude-optimized prompt)\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "print(f\"Start time: {datetime.datetime.now()}\")\n",
    "\n",
    "for i, chapter in enumerate(chapters[0::]):\n",
    "    try:\n",
    "        prompt = f\"\"\"Generate a list of 6 multiple choice questions about the chapter below. \n",
    "\n",
    "            For each question, provide 4 answer choices labeled A, B, C and D, with the correct answer labeled in parentheses at the end. \n",
    "\n",
    "            Make the questions and answers brief and clear. Do not use bullet points, brackets or XML tags.\n",
    "\n",
    "            Follow this template:\n",
    "\n",
    "            Q: [Question?]\n",
    "            A) [Choice 1]  \n",
    "            B) [Choice 2]\n",
    "            C) [Choice 3]  \n",
    "            D) [Choice 4]\n",
    "            A: (Letter) [Correct Answer]\n",
    "\n",
    "            <chapter>\n",
    "            {chapter.strip()} \n",
    "            </chapter>\"\"\"\n",
    "\n",
    "        chapter_summary = create_summary(prompt)\n",
    "        chapter_summary = f\"\\nChapter {i + 1}:\\n{chapter_summary}\\n\\n\"\n",
    "        summary += chapter_summary\n",
    "        print(f\"Chapter {i + 1}/{len(chapters)} completed...\", end=\"\\r\")\n",
    "    except Exception as ex:\n",
    "        chapter_summary = f\"Chapter {i + 1}/{len(chapters)} failed: {ex}\"\n",
    "        print(chapter_summary)\n",
    "        summary += chapter_summary\n",
    "\n",
    "print(f\"Finish time: {datetime.datetime.now()}\")\n",
    "\n",
    "with open(f\"./output/dracula_multiple_choice_claude_optimized.txt\", \"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae4211-0b6c-4554-865d-1bdf9bed0996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
